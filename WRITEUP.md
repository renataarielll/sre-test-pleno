# üìë Relat√≥rio T√©cnico Detalhado ‚Äì SRE Challenge (Pleno)

## 1. Introdu√ß√£o e Escopo do Projeto

Este documento detalha a implementa√ß√£o do projeto sre-test-pleno, desenvolvido para o desafio t√©cnico de SRE. O foco principal foi a cria√ß√£o de um ecossistema orquestrado que garante observabilidade total, escalabilidade din√¢mica e resili√™ncia, utilizando a filosofia de Infrastructure as Code (IaC).

## 2. Arquitetura da Solu√ß√£o e Decis√µes de Design

### 2.1 Camada de Aplica√ß√£o (FastAPI)

**Framework:** Optou-se pelo FastAPI pela sua performance ass√≠ncrona e suporte nativo a health checks.

**Sa√∫de e Prontid√£o:** Implementa√ß√£o de endpoints /health (Liveness) e /ready (Readiness) para gest√£o inteligente do ciclo de vida dos pods.

### 2.2 Estrat√©gia de Containeriza√ß√£o (Docker)

**Multi-stage Build:** T√©cnica aplicada para garantir imagens leves (baseadas em python:3.11-slim) e seguras, eliminando ferramentas de build do ambiente de execu√ß√£o.

**Seguran√ßa (Hardening):** Execu√ß√£o com utilizador n√£o-privilegiado (USER appuser), reduzindo a superf√≠cie de ataque.

### 2.3 Orquestra√ß√£o e Resili√™ncia (Kubernetes)

**Gest√£o de Recursos:** Defini√ß√£o rigorosa de requests e limits (CPU/Mem√≥ria) para evitar o erro de OOMKilled.

**Self-Healing:** Configura√ß√£o de Probes para rein√≠cio autom√°tico em caso de falhas cr√≠ticas.

## 3. Di√°rio de Bordo: Dificuldades Enfrentadas e Debugs Realizados

Demonstrar a capacidade de diagn√≥stico foi parte fundamental do processo:

### 3.1 Corre√ß√£o do Metrics Server e HPA

**Dificuldade:** O HPA exibia o consumo de CPU como <unknown>.

**Debug:** Atrav√©s de kubectl logs no namespace kube-system, identifiquei que o Metrics Server n√£o comunicava com os n√≥s devido a certificados auto-assinados.

**Resolu√ß√£o:** Reconfigura√ß√£o do addon do Minikube com as flags de seguran√ßa adequadas para permitir a monitoriza√ß√£o de recursos.

### 3.2 Parsing de Logs com Grok (ELK)

**Dificuldade:** Os logs eram ingeridos como texto bruto, impedindo a an√°lise de lat√™ncia.

**Debug:** Utilizei o Grok Debugger e testes no stdout do Logstash para ajustar o padr√£o de regex.

**Resolu√ß√£o:** Cria√ß√£o de um pipeline que extrai level, endpoint e latency (convertendo este √∫ltimo para integer), permitindo dashboards de performance reais.

### 3.3 Conetividade do Filebeat

***Dificuldade:** Falha na leitura dos logs no caminho /var/log/pods.

**Debug:** O kubectl describe pod revelou problemas de permiss√µes no mount do volume.

**Resolu√ß√£o:** Ajuste do SecurityContext no DaemonSet do Filebeat para garantir acesso de leitura aos logs do host.

### 3.4 Refinamento de Probes e Readiness

**Dificuldade:** Identifiquei via logs (kubectl logs) que o Kubernetes estava recebendo erros 404 no endpoint /ready.

**Debug:** Percebi uma inconsist√™ncia entre o manifesto do Kubernetes e as rotas implementadas na aplica√ß√£o FastAPI.

**Resolu√ß√£o:** Unifiquei os endpoints de Liveness e Readiness para /health e realizei um novo rollout. O resultado foi uma estabiliza√ß√£o imediata dos logs, com 100% das requisi√ß√µes retornando HTTP 200, garantindo que o Load Balancer apenas envie tr√°fego para Pods totalmente operacionais.

## 4. Observabilidade e Escalabilidade (O que foi entregue)

### 4.1 M√©tricas (Prometheus & Grafana)

**Service Discovery:** Implementado via Kubernetes Annotations, permitindo que o Prometheus encontre a aplica√ß√£o automaticamente sem interven√ß√£o manual.

### 4.2 Logs (ELK Stack)

**Fluxo:** Filebeat (coleta) -> Logstash (filtro/parsing) -> Elasticsearch (armazenamento) -> Kibana (visualiza√ß√£o).

### 4.3 Escalabilidade (HPA)

**Valida√ß√£o:** Teste de carga realizado com load-generator. O sistema escalou de 2 para 5 r√©plicas ao atingir 70% de CPU, comprovando a efic√°cia da configura√ß√£o de auto-scaling.

## 5. Evolu√ß√£o e Melhoria Cont√≠nua

O projeto foi desenhado para ser expans√≠vel, com os seguintes pr√≥ximos passos planeados:

### 5.1 Implementa√ß√£o de OpenTelemetry (OTel)

A inclus√£o do OpenTelemetry ser√° um aditivo de valor √† stack atual (Prometheus/ELK):

**Tracing Distribu√≠do:** Adicionar rastreio de ponta a ponta para visualizar o fluxo das requisi√ß√µes entre servi√ßos e base de dados.

**Unifica√ß√£o de Sinais:** Utilizar o OTel Collector como um gateway √∫nico para receber m√©tricas e traces, podendo exportar simultaneamente para o Prometheus e para ferramentas de tracing como o Jaeger.

**Contextualiza√ß√£o:** Correlacionar um log espec√≠fico (do ELK) com um trace ID (do OTel), reduzindo drasticamente o tempo de diagn√≥stico (MTTR).

### 5.2 Efici√™ncia de Recursos e FinOps

**Justificativa de Requests/Limits:** A defini√ß√£o cuidadosa dos recursos (requests de 100m de CPU e 128Mi de mem√≥ria) n√£o foi apenas para estabilidade, mas para otimiza√ß√£o de custos. Ao definir Requests baixos, permitimos uma maior densidade de Pods por N√≥ no cluster, reduzindo o gasto com infraestrutura.

**HPA como Ferramenta de Economia:** O uso do Autoscaling garante que s√≥ pagaremos por 5 r√©plicas durante picos de tr√°fego. Em hor√°rios de baixa demanda, o sistema retorna para 2 r√©plicas, evitando o desperd√≠cio de recursos ociosos.

### 5.3 Seguran√ßa e Automa√ß√£o

**Network Policies:** Implementa√ß√£o de isolamento de rede L3/L4 entre namespaces.

**GitOps:** Integra√ß√£o com ArgoCD para garantir que o cluster reflita sempre o estado do reposit√≥rio.

## 6. Conclus√£o

Este projeto reflete o compromisso com a Engenharia de Confiabilidade. Mais do que uma aplica√ß√£o funcional, entregou-se um ecossistema documentado, resiliente e preparado para a integra√ß√£o de tecnologias modernas como o OpenTelemetry.

Autora: **Renata Delgado**